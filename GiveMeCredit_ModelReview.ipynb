{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travail pour analyser notre dataset, notre modèle et nos résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On récupère le fichier Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigml.api import BigML\n",
    "from pandas import read_csv\n",
    "import json\n",
    "\n",
    "df = read_csv('csv_file/train_full.csv')\n",
    "api = BigML(project='project/5d94a454eba31d46690001d1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Envoi sur BigML\n",
    "\n",
    "##### Création source et dataset pour pouvoir travailler sur BigML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation d'une source\n",
    "source = api.create_source('csv_file/train_full.csv')\n",
    "api.ok(source)\n",
    "# Creation d'un dataset ( = source )\n",
    "origin_dataset = api.create_dataset(source)\n",
    "api.ok(origin_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split du dataset Train/Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = api.create_dataset(\n",
    "    origin_dataset, {\"name\": \"train_set\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n",
    "validation_set = api.create_dataset(\n",
    "    origin_dataset, {\"name\": \"validation_set\",\n",
    "                     \"sample_rate\": 0.8, \"seed\": \"my seed\",\n",
    "                     \"out_of_bag\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création fichier csv des 2 sets qui serviront pour l'amélioration continue\n",
    "- cf notebook : GiveMeCredit_ContinuousImprovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csv_file/validation_set.csv'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bigml.api import BigML\n",
    "from pandas import read_csv\n",
    "\n",
    "api.ok(train_set)\n",
    "api.download_dataset(train_set, filename='csv_file/train_set.csv')\n",
    "api.ok(validation_set)\n",
    "api.download_dataset(validation_set, filename='csv_file/validation_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création d'un modele ensemble sur la partie train du split du dataset TrainFull (On precise quelle est la donnée que l'on recherche)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = api.create_ensemble(train_set , {\"objective_field\" : \"SeriousDlqin2yrs\"})\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération des données d'évaluation du modèle sur validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "evaluation = api.create_evaluation(ensemble, validation_set)\n",
    "api.ok(evaluation)\n",
    "%store evaluation\n",
    "eval = pandas.DataFrame(evaluation[\"object\"][\"result\"][\"model\"][\"confusion_matrix\"], index=[\"F\", \"P\"], columns=[\"F\", \"P\"])\n",
    "print(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction du modèle sur le validation_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_prediction_validation_set = api.create_batch_prediction(ensemble, validation_set,{\"header\": True, \"all_fields\": True,\"prediction_name\": \"my_prediction\", \"probability\": True, \"probabilities\": True})\n",
    "api.ok(batch_prediction_validation_set)\n",
    "api.download_batch_prediction(batch_prediction_validation_set,filename='BatchPrediction/Validation_set_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Création de la matrice de confusion\n",
    "\n",
    "##### Cette matrice sert à diviser les prédictions en 4 catégories :\n",
    "- Vrai positifs : le modèle a prédit 1 et a eu raison\n",
    "- Vrai négatifs : le modèle a prédit 0 et a eu raison\n",
    "- Faux positifs : le modèle a prédit 1 et s'est trompé\n",
    "- Faux négatifs : le modèle a prédit 0 et s'est trompé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "prediction = pandas.read_csv('BatchPrediction/Validation_set_prediction.csv')\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_confusion_method(row):\n",
    "    x = \"TN\"\n",
    "    if row['SeriousDlqin2yrs'] == 1:\n",
    "        if row['my_prediction'] == 1:\n",
    "            x = \"TP\"\n",
    "        else:\n",
    "            x = \"FN\"\n",
    "    else:\n",
    "        if row['my_prediction'] == 1:\n",
    "            x = \"FP\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des valeurs de la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_confusion():\n",
    "    prediction['Error'] = prediction.apply(matrix_confusion_method, axis=1)\n",
    "    return prediction['Error'].value_counts()\n",
    "\n",
    "matrix_confusion = get_matrix_confusion()\n",
    "print(matrix_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de l'accuracy de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (matrix_confusion['TP'] + matrix_confusion ['TN'])/300\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapes du travail d'analyse d'erreurs  :\n",
    "- créer colonne \"erreur\" : i.e. colonne où on décrit si c'est un FN, FP, TN, TP\n",
    "- analyser les plus grosses erreurs (probability très proche de 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mise en forme de notre fichier pour analyse des erreurs les plus importantes\n",
    "\n",
    "##### Ici, on a décidé de sélectionner les 100 plus grosses erreurs du modèle :\n",
    "- C'est-à-dire que le modèle a fait une prédiction avec une probabilité très importante (ou avec un taux de confiance très fort) mais la prédiction est mauvaise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = prediction.loc[prediction['Error'].isin([\"FN\", \"FP\"])]\n",
    "filtered = (filtered.nlargest(100, 'probability'))\n",
    "\n",
    "filtered.to_csv('csv_file/100mistakes.csv')\n",
    "filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# table = [cost_threshold(n/10000) for n in range(0,10000)]\n",
    "# plt.plot(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
